{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collect-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input,Conv2D,Dense,Dropout,Lambda, GlobalAveragePooling2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform, he_uniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# from pylab import dist\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../precalculated_files_mel/samplespace/\"\n",
    "\n",
    "# songs = list(Path(source_dir).glob('*.png'))\n",
    "img = Image.open(source_dir+\"000190.png\")\n",
    "width,height = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aging-salvation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 496)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(img)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opened-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# for i in range(3):\n",
    "#     plt.subplot(1, 3, 1 + i)\n",
    "# #         plt.imshow(np.reshape(examples[i], (x_train_w, x_train_h)), cmap='binary')\n",
    "#     plt.imshow(Image.open(songs[i]), cmap=\"gray\")\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virgin-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_ind = pd.read_csv(\"../csvs/samplespace.csv\") \n",
    "len(tracks_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-information",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assigned-favor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>track_title</th>\n",
       "      <th>track_genre_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>38351</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Memories of a machine</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>38352</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Business of panic (instrumental)</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>38353</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9170</td>\n",
       "      <td>Sunny day (instrumental)</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>38354</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Not free but not afraid (instrumental)</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>38365</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Stop that mission (instrumental)</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>54443</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Sunny Day (Vocal Version)</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>55231</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>All Back To Mine</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>55232</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Stop That Mission</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>55233</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Kingdom Come</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>55234</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>District 6</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>55235</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Love &amp; Relationshit</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>55236</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Sunny Day</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>55237</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Business Of Panic</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>55238</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Not Free But Not Afraid</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>55240</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Memories Of A Machine</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>55241</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>Serious Problem</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>55242</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>The Essence Of Bottled Light</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>56030</td>\n",
       "      <td>Mastermind XS</td>\n",
       "      <td>9169</td>\n",
       "      <td>All The Stars</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     track_id    artist_name  artist_id  \\\n",
       "497     38351  Mastermind XS       9169   \n",
       "498     38352  Mastermind XS       9169   \n",
       "499     38353  Mastermind XS       9170   \n",
       "500     38354  Mastermind XS       9169   \n",
       "501     38365  Mastermind XS       9169   \n",
       "843     54443  Mastermind XS       9169   \n",
       "859     55231  Mastermind XS       9169   \n",
       "860     55232  Mastermind XS       9169   \n",
       "861     55233  Mastermind XS       9169   \n",
       "862     55234  Mastermind XS       9169   \n",
       "863     55235  Mastermind XS       9169   \n",
       "864     55236  Mastermind XS       9169   \n",
       "865     55237  Mastermind XS       9169   \n",
       "866     55238  Mastermind XS       9169   \n",
       "867     55240  Mastermind XS       9169   \n",
       "868     55241  Mastermind XS       9169   \n",
       "869     55242  Mastermind XS       9169   \n",
       "906     56030  Mastermind XS       9169   \n",
       "\n",
       "                                track_title track_genre_top  \n",
       "497                   Memories of a machine   International  \n",
       "498        Business of panic (instrumental)   International  \n",
       "499                Sunny day (instrumental)   International  \n",
       "500  Not free but not afraid (instrumental)   International  \n",
       "501        Stop that mission (instrumental)   International  \n",
       "843               Sunny Day (Vocal Version)   International  \n",
       "859                        All Back To Mine   International  \n",
       "860                       Stop That Mission   International  \n",
       "861                            Kingdom Come   International  \n",
       "862                              District 6   International  \n",
       "863                     Love & Relationshit   International  \n",
       "864                               Sunny Day   International  \n",
       "865                       Business Of Panic   International  \n",
       "866                 Not Free But Not Afraid   International  \n",
       "867                   Memories Of A Machine   International  \n",
       "868                         Serious Problem   International  \n",
       "869            The Essence Of Bottled Light   International  \n",
       "906                           All The Stars   International  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixing outlier\n",
    "tracks_ind[tracks_ind['artist_name']==\"Mastermind XS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "received-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_ind.loc[tracks_ind.artist_name=='Mastermind XS', \"artist_id\"] = 9169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saving-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_ind[\"track_id\"] = [\"%06.0f\" % x for x in tracks_ind[\"track_id\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "varying-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(tracks_ind.artist_id))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "found-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_500():\n",
    "    tracks_set = np.zeros((500,369,496))\n",
    "    i = 0\n",
    "    for index,row in tracks_ind[:500].iterrows():\n",
    "        tracks_set[i] = np.asarray(Image.open(source_dir+tracks_ind.iloc[index][\"track_id\"]+\".png\"))/255\n",
    "        i+=1\n",
    "    tracks_set = tracks_set.reshape(test_set.shape[0], height, width, 1)\n",
    "    \n",
    "    return tracks_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "listed-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triplet():\n",
    "    x_anchor = np.zeros((height,width)) #Gonna have issues with image (369,496,1) not (369,496)\n",
    "    x_pos = np.zeros((height,width))\n",
    "    x_neg = np.zeros((height,width))\n",
    "    \n",
    "    rand_ind = random.randint(0, len(tracks_ind))\n",
    "    x_anchor = np.asarray(Image.open(source_dir+tracks_ind.iloc[rand_ind][\"track_id\"]+\".png\"))/255\n",
    "    y = tracks_ind.loc[rand_ind][\"artist_id\"]\n",
    "    # y is an int32(artist_id is int) while track_id is str\n",
    "    \n",
    "    indices_for_pos = np.squeeze(np.where(tracks_ind['artist_id'] == y))   #selcting songs only belonging to same artist\n",
    "    indices_for_neg = np.squeeze(np.where(tracks_ind['artist_id'] != y))  #diff artists\n",
    "\n",
    "    x_pos_id = tracks_ind.iloc[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]] #getting random pos id from df\n",
    "    x_neg_id = tracks_ind.iloc[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]] #getting neg id from df\n",
    "    x_pos = np.asarray(Image.open(source_dir+x_pos_id[\"track_id\"]+\".png\"))/255 #normalizing to 0-1\n",
    "    x_neg = np.asarray(Image.open(source_dir+x_neg_id[\"track_id\"]+\".png\"))/255\n",
    "    \n",
    "    x_anchor = x_anchor.reshape(1,x_anchor.shape[0], x_anchor.shape[1],1)\n",
    "    x_pos = x_pos.reshape(1,x_pos.shape[0], x_pos.shape[1],1)\n",
    "    x_neg = x_neg.reshape(1,x_neg.shape[0], x_neg.shape[1],1)\n",
    "    \n",
    "    return [x_anchor,x_pos,x_neg]\n",
    "\n",
    "def create_hard_batch(alpha,batch_size=256):\n",
    "    x_anchors = np.zeros((batch_size, height,width,1))\n",
    "    x_positives = np.zeros((batch_size, height,width,1))\n",
    "    x_negatives = np.zeros((batch_size, height,width,1))\n",
    "    \n",
    "    ini_batch = [] \n",
    "    hard_batch = []\n",
    "    not_hard_batch = []\n",
    "    batch_losses = []\n",
    "    rand_batches = []\n",
    "    \n",
    "    sample_size = 512\n",
    "    \n",
    "    for i in range(0,sample_size):\n",
    "        ini_batch.append(make_triplet())\n",
    "        a_emb = embedding_model.predict(ini_batch[i][0])\n",
    "        p_emb = embedding_model.predict(ini_batch[i][1])\n",
    "        n_emb = embedding_model.predict(ini_batch[i][2])\n",
    "        \n",
    "        dAP = np.linalg.norm(a_emb -p_emb) #Should this be negated like in compute_prob func?\n",
    "        dAN = np.linalg.norm(a_emb- n_emb)\n",
    "        \n",
    "        if(dAN - dAP < alpha and dAN >= dAP):\n",
    "            hard_batch.append(ini_batch[i])\n",
    "        elif(dAN > dAP):\n",
    "            not_hard_batch.append(ini_batch[i])\n",
    "    \n",
    "    if(len(hard_batch)<batch_size): #batch prob 256\n",
    "        alpha += 0.05 # cuz we want up by 0.05 increments\n",
    "        remaining = batch_size-len(hard_batch) #later pick closest best hard\n",
    "        remaining = not_hard_batch[:remaining]\n",
    "    else:\n",
    "        remaining = not_hard_batch[0:0]\n",
    "        \n",
    "    final_batch = hard_batch+remaining\n",
    "    \n",
    "    for i in range(0, len(final_batch)):\n",
    "        x_anchors[i] = final_batch[i][0]\n",
    "        x_positives[i] = final_batch[i][1]\n",
    "        x_negatives[i] = final_batch[i][2]\n",
    "        \n",
    "#     x_anchors =  x_anchors.reshape(x_anchors.shape[0], height, width, 1)\n",
    "#     x_positives =  x_positives.reshape(x_positives.shape[0], height, width, 1)\n",
    "#     x_negatives =  x_negatives.reshape(x_negatives.shape[0], height, width, 1)\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives],alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "received-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "alpha = 0.2\n",
    "emb_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "western-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_model(input_shape=(height,width,1),emb_size=32): #inp shape has to be of form (height,width)\n",
    "    inputs = Input(input_shape);\n",
    "    x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(32, (5,5), padding=\"same\",  activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "#     x = Flatten()(x)\n",
    "    \n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     Output = Dense(32, activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    outputs = Dense(emb_size,kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(pooledOutput)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (data.shape,1)\n",
    "print(input_shape)\n",
    "def SNN(embedding_model):\n",
    "    input_anchor = Input(shape=input_shape)\n",
    "    input_positive = Input(shape=input_shape)\n",
    "    input_negative = Input(shape=input_shape)\n",
    "    \n",
    "    embedding_anchor = embedding_model(input_anchor)\n",
    "    embedding_positive = embedding_model(input_positive)\n",
    "    embedding_negative = embedding_model(input_negative)\n",
    "    \n",
    "    output = tf.keras.layers.concatenate([embedding_anchor,embedding_positive, embedding_negative],axis=1) \n",
    "    # Weird thing where only tf.keras works not Concatenate\n",
    "    \n",
    "    siamese_net = Model([input_anchor, input_positive, input_negative], output)\n",
    "    \n",
    "    siamese_net.summary()\n",
    "    \n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rapid-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true,y_pred):\n",
    "    anchor, pos, neg = y_pred[:,:emb_size],y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size]\n",
    "    dAP = tf.norm(anchor-pos)\n",
    "    dAN = tf.norm(anchor-neg)\n",
    "    return tf.maximum(pos - neg + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "polish-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=256, alpha=0.2):\n",
    "    while True:\n",
    "        x,alpha = create_hard_batch(alpha,batch_size)\n",
    "        y = np.zeros((batch_size, 3*emb_size))\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "racial-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPY PASTE from https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352\n",
    "# Well not really updated but func is genrally same\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings \n",
    "        X : tensor of shape (m,h,w,1) containing pics to evaluate => m is 500\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2) # => 500C2 => like 124,000\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all imgs with current embedding network\n",
    "    embeddings = embedding_model.predict(X)\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    # For each img in the evaluation set\n",
    "    for i in range(m):\n",
    "            # Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                # compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                    #print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tSAME\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                    #print(\"{3}:{0} vs {1} : {2}\\tDIFF\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                k += 1\n",
    "    return probs, y\n",
    "\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    return fpr, tpr, thresholds,auc\n",
    "\n",
    "def draw_roc(fpr, tpr,thresholds, auc):\n",
    "    #find threshold\n",
    "    targetfpr=1e-3\n",
    "    _, idx = find_nearest(fpr,targetfpr)\n",
    "    threshold = thresholds[idx]\n",
    "    recall = tpr[idx]\n",
    "    \n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold) ))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "\n",
    "def draw_interdist(network, epochs,test_set):\n",
    "    interdist = compute_interdist(network,test_set)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(num_classes):\n",
    "        data.append(np.delete(interdist[i,:],[i]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Evaluating embeddings distance from each other after {0} epochs'.format(epochs))\n",
    "    ax.set_ylim([0,3])\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Distance')\n",
    "    ax.boxplot(data,showfliers=False,showbox=True)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs,np.arange(num_classes))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def compute_interdist(network,test_set):\n",
    "    '''\n",
    "    Computes sum of distances between all classes embeddings on our reference test image: \n",
    "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
    "        A good model should have a large distance between all theses embeddings\n",
    "        \n",
    "    Returns:\n",
    "        array of shape (num_classes,num_classes) \n",
    "    '''\n",
    "    res = np.zeros((num_classes,num_classes))\n",
    "    \n",
    "    ref_images = np.zeros((num_classes, height,width, 1))\n",
    "    \n",
    "    #generates embeddings for reference images\n",
    "    for i in range(num_classes):\n",
    "        ref_images[i,:,:,:] = test_set_imgs[i,:,:,:]\n",
    "    \n",
    "    ref_embeddings = network.predict(ref_images)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "#             res[i,j] = dist(ref_embeddings[i],ref_embeddings[j]) \n",
    "            # dist func doesnt work\n",
    "            res[i,j] = compute_dist(ref_embeddings[i],ref_embeddings[j]) #Should it be negative?\n",
    "    return res\n",
    "\n",
    "def DrawTestImage(network, images, refidx=0):\n",
    "    '''\n",
    "    Evaluate some pictures vs some samples in the test set\n",
    "        image must be of shape(1,w,h,c)\n",
    "    \n",
    "    Returns\n",
    "        scores : result of the similarity scores with the basic images => (N)\n",
    "    \n",
    "    '''\n",
    "    nbimages = images.shape[0]\n",
    "    \n",
    "    print(\"Predicting embeding\")\n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    \n",
    "    print(\"Computing dist\")\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((num_classes,height,width,1))\n",
    "    for i in range(num_classes):\n",
    "        images_at_this_index_are_of_class_i = np.squeeze(np.where(test_set.artist_id == i))\n",
    "#         ref_images[i,:] = x_test[images_at_this_index_are_of_class_i[refidx]]\n",
    "        ref_images[i,:,:,:] = test_set_imgs[images_at_this_index_are_of_class_i[refidx]] #prob will be broken\n",
    "        \n",
    "        \n",
    "    ref_embedings = network.predict(ref_images)\n",
    "            \n",
    "    for i in range(nbimages):\n",
    "        # Prepare the figure\n",
    "        fig=plt.figure(figsize=(16,2))\n",
    "        subplot = fig.add_subplot(1,num_classes+1,1)\n",
    "        plt.axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        # Draw this image    \n",
    "        plt.imshow(np.reshape(images[i], (width, height)),vmin=0, vmax=1,cmap='Greys') #maybe (height,width)\n",
    "        subplot.title.set_text(\"Test image\")\n",
    "            \n",
    "        for ref in range(num_classes):\n",
    "            #Compute distance between this images and references\n",
    "            dist = compute_dist(image_embedings[i,:],ref_embedings[ref,:])\n",
    "            #Draw\n",
    "            subplot = fig.add_subplot(1,num_classes+1,plotidx)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(np.reshape(ref_images[ref, :], (width, height)),vmin=0, vmax=1,cmap='Greys')\n",
    "            subplot.title.set_text((\"Class {0}\\n{1:.3e}\".format(ref,dist)))\n",
    "            plotidx += 1\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(embedding_model, epochs=0):\n",
    "    test_set_imgs = np.zeros((500,height,width))\n",
    "    test_set = get_test_set(500)\n",
    "    i = 0\n",
    "    for index,rowdata  in test_set.iterrows():\n",
    "        test_set_imgs[i] = np.asarray(Image.open(source_dir+rowdata[\"track_id\"]+\".png\"))/255\n",
    "        i+=1\n",
    "    test_set_imgs = test_set_imgs.reshape(test_set.shape[0], height, width, 1)\n",
    "    \n",
    "    probs, yprob = compute_probs(embedding_model, test_set_imgs, test_set[:500].artist_id.array)\n",
    "    fpr, tpr, thresholds, auc = compute_metrics(probs,yprob)\n",
    "    draw_roc(fpr, tpr, thresholds, auc)\n",
    "    draw_interdist(embedding_model, epochs,test_set)\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         DrawTestImage(embedding_model, np.expand_dims(test_set_imgs[i],axis=0)) \n",
    "#Maybe later cuz gotta fix abv func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "fiscal-sunday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "fiscal-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set(n_samples=500): #Equally get each class atleast 1\n",
    "    test_set2 = tracks_ind.groupby(\"artist_id\").sample(n=2) \n",
    "    first_half = test_set2[test_set2.duplicated(subset='artist_id', keep=\"first\")] #get first copy 354 one song \n",
    "    second_half = test_set2[test_set2.duplicated(subset='artist_id', keep=\"last\")] #get last half 146 (500-354)\n",
    "    full_fhun = pd.concat([first_half, second_half.sample(n_samples - len(first_half))])\n",
    "    return full_fhun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "crucial-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More fns unused as to be adapted\n",
    "\n",
    "'''def generate_prototypes(x_data, y_data, embedding_model):\n",
    "    classes = np.unique(y_data)\n",
    "    prototypes = {}\n",
    "\n",
    "    for c in classes:\n",
    "        #c = classes[0]\n",
    "        # Find all images of the chosen test class\n",
    "        locations_of_c = np.where(y_data == c)[0]\n",
    "\n",
    "        imgs_of_c = x_data[locations_of_c]\n",
    "\n",
    "        imgs_of_c_embeddings = embedding_model.predict(imgs_of_c)\n",
    "\n",
    "        # Get the median of the embeddings to generate a prototype for the class (reshaping for PCA)\n",
    "        prototype_for_c = np.median(imgs_of_c_embeddings, axis = 0).reshape(1, -1)\n",
    "        # Add it to the prototype dict\n",
    "        prototypes[c] = prototype_for_c\n",
    "        \n",
    "    return prototypes\n",
    "         \n",
    "def test_one_shot_prototypes(network, sample_embeddings):\n",
    "    distances_from_img_to_test_against = []\n",
    "    # As the img to test against is in index 0, we compare distances between img@0 and all others\n",
    "    for i in range(1, len(sample_embeddings)):\n",
    "        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\n",
    "    # As the correct img will be at distances_from_img_to_test_against index 0 (sample_imgs index 1),\n",
    "    # If the smallest distance in distances_from_img_to_test_against is at index 0, \n",
    "    # we know the one shot test got the right answer\n",
    "    is_min = distances_from_img_to_test_against[0] == min(distances_from_img_to_test_against)\n",
    "    is_max = distances_from_img_to_test_against[0] == max(distances_from_img_to_test_against)\n",
    "    return int(is_min and not is_max)\n",
    "    \n",
    "def n_way_accuracy_prototypes(n_val, n_way, network):\n",
    "    num_correct = 0\n",
    "    \n",
    "    for val_step in range(n_val):\n",
    "        num_correct += load_one_shot_test_batch_prototypes(n_way, network)\n",
    "        \n",
    "    accuracy = num_correct / n_val * 100\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "def load_one_shot_test_batch_prototypes(n_way, network):\n",
    "    \n",
    "    labels = np.unique(y_test)\n",
    "    # Reduce the label set down from size n_classes to n_samples \n",
    "    labels = np.random.choice(labels, size = n_way, replace = False)\n",
    "\n",
    "    # Choose a class as the test image\n",
    "    label = random.choice(labels)\n",
    "    # Find all images of the chosen test class\n",
    "    imgs_of_label = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select a test image of the selected class, return it's index\n",
    "    img_of_label_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Expand the array at the selected indexes into useable images\n",
    "    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\n",
    "    \n",
    "    sample_embeddings = []\n",
    "    # Get the anchor image embedding\n",
    "    anchor_prototype = network.predict(img_of_label)\n",
    "    sample_embeddings.append(anchor_prototype)\n",
    "    \n",
    "    # Get the prototype embedding for the positive class\n",
    "    positive_prototype = prototypes[label]\n",
    " \n",
    "    sample_embeddings.append(positive_prototype)\n",
    "    \n",
    "    # Get the negative prototype embeddings\n",
    "    # Remove the selected test class from the list of labels based on it's index \n",
    "    label_idx_in_labels = np.where(labels == label)[0]\n",
    "    other_labels = np.delete(labels, label_idx_in_labels)\n",
    "    \n",
    "    # Get the embedding for each of the remaining negatives\n",
    "    for other_label in other_labels:\n",
    "        negative_prototype = prototypes[other_label]\n",
    "        sample_embeddings.append(negative_prototype)\n",
    "                \n",
    "    correct = test_one_shot_prototypes(network, sample_embeddings)\n",
    "\n",
    "    return correct\n",
    "\n",
    "\n",
    "def visualise_n_way_prototypes(n_samples, network):\n",
    "    labels = np.unique(y_test)\n",
    "    # Reduce the label set down from size n_classes to n_samples \n",
    "    labels = np.random.choice(labels, size = n_samples, replace = False)\n",
    "\n",
    "    # Choose a class as the test image\n",
    "    label = random.choice(labels)\n",
    "    # Find all images of the chosen test class\n",
    "    imgs_of_label = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select a test image of the selected class, return it's index\n",
    "    img_of_label_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Get another image idx that we know is of the test class for the sample set\n",
    "    label_sample_img_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Expand the array at the selected indexes into useable images\n",
    "    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\n",
    "    label_sample_img = np.expand_dims(x_test[label_sample_img_idx],axis=0)\n",
    "    \n",
    "    # Make the first img in the sample set the chosen test image, the second the other image\n",
    "    sample_imgs = np.empty((0, x_test_w_h))\n",
    "    sample_imgs = np.append(sample_imgs, img_of_label, axis=0)\n",
    "    sample_imgs = np.append(sample_imgs, label_sample_img, axis=0)\n",
    "    \n",
    "    sample_embeddings = []\n",
    "    \n",
    "    # Get the anchor embedding image\n",
    "    anchor_prototype = network.predict(img_of_label)\n",
    "    sample_embeddings.append(anchor_prototype)\n",
    "    \n",
    "    # Get the prototype embedding for the positive class\n",
    "    positive_prototype = prototypes[label]\n",
    "    sample_embeddings.append(positive_prototype)\n",
    "\n",
    "    # Get the negative prototype embeddings\n",
    "    # Remove the selected test class from the list of labels based on it's index \n",
    "    label_idx_in_labels = np.where(labels == label)[0]\n",
    "    other_labels = np.delete(labels, label_idx_in_labels)\n",
    "    # Get the embedding for each of the remaining negatives\n",
    "    for other_label in other_labels:\n",
    "        negative_prototype = prototypes[other_label]\n",
    "        sample_embeddings.append(negative_prototype)\n",
    "        \n",
    "        # Find all images of the other class\n",
    "        imgs_of_other_label = np.where(y_test == other_label)[0]\n",
    "        # Randomly select an image of the selected class, return it's index\n",
    "        another_sample_img_idx = random.choice(imgs_of_other_label)\n",
    "        # Expand the array at the selected index into useable images\n",
    "        another_sample_img = np.expand_dims(x_test[another_sample_img_idx],axis=0)\n",
    "        # Add the image to the support set\n",
    "        sample_imgs = np.append(sample_imgs, another_sample_img, axis=0)\n",
    "    \n",
    "    distances_from_img_to_test_against = []\n",
    "    \n",
    "    # As the img to test against is in index 0, we compare distances between img@0 and all others\n",
    "    for i in range(1, len(sample_embeddings)):\n",
    "        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\n",
    "        \n",
    "    # + 1 as distances_from_img_to_test_against doesn't include the test image\n",
    "    min_index = distances_from_img_to_test_against.index(min(distances_from_img_to_test_against)) + 1\n",
    "    \n",
    "    return sample_imgs, min_index'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fatty-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding model... \n",
      "\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 369, 496, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 369, 496, 16)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 184, 248, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 184, 248, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 184, 248, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 92, 124, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 92, 124, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 90, 122, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 45, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 45, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 43, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 21, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 21, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 19, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 9, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 107,680\n",
      "Trainable params: 107,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Generating SNN... \n",
      "\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 369, 496)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 369, 496)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 369, 496)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 32)           107680      input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96)           0           model_2[0][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 107,680\n",
      "Trainable params: 107,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-484f43108f56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Store visualisations of the embeddings using PCA for display next to \"after training\" for comparisons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mnum_vis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;31m# Take only the first num_vis elements of the test set to visualise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0membeddings_before_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_first_500\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mdecomposed_embeddings_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_before_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-740bd28fb786>\u001b[0m in \u001b[0;36mget_first_500\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtracks_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtracks_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"track_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtracks_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracks_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtracks_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_set' is not defined"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 15 #100\n",
    "steps_per_epoch = int(tracks_ind.shape[0]/batch_size)\n",
    "# val_steps = int(x_test.shape[0]/batch_size)\n",
    "alpha = 0.2\n",
    "num_hard = int(batch_size * 0.5) # Number of semi-hard triplet examples in the batch\n",
    "lr = 0.00006\n",
    "optimiser = 'Adam'\n",
    "emb_size = 32 # 10 in mnist\n",
    "input_size = (369,496,1)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # Create the embedding model\n",
    "    print(\"Generating embedding model... \\n\")\n",
    "    embedding_model = make_embedding_model(emb_size=emb_size) #maybe dec input size (369,496) \n",
    "    \n",
    "    print(\"\\nGenerating SNN... \\n\")\n",
    "    # Create the SNN\n",
    "    siamese_net = SNN(embedding_model)\n",
    "    # Compile the SNN\n",
    "    optimiser_obj = Adam(lr = lr)\n",
    "    siamese_net.compile(loss=triplet_loss, optimizer= optimiser_obj)\n",
    "    \n",
    "    # Store visualisations of the embeddings using PCA for display next to \"after training\" for comparisons\n",
    "    num_vis = 500 # Take only the first num_vis elements of the test set to visualise\n",
    "    embeddings_before_train = embedding_model.predict(get_first_500())\n",
    "    pca = PCA(n_components=2)\n",
    "    decomposed_embeddings_before = pca.fit_transform(embeddings_before_train)\n",
    "\n",
    "print(\"\\nEvaluating the model without training for a baseline...\\n\")\n",
    "evaluate(embedding_model)\n",
    "\n",
    "#### DO CALLBACKS LATER\n",
    "\n",
    "# Save model configs to JSON\n",
    "# model_json = siamese_net.to_json()\n",
    "# with open(os.path.join(logdir, \"siamese_config.json\"), \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "#     json_file.close()\n",
    "    \n",
    "# model_json = embedding_model.to_json()\n",
    "# with open(os.path.join(logdir, \"embedding_config.json\"), \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "#     json_file.close()\n",
    "    \n",
    "# hyperparams = {'batch_size' : batch_size,\n",
    "#               'epochs' : epochs, \n",
    "#                'steps_per_epoch' : steps_per_epoch, \n",
    "#                'val_steps' : val_steps, \n",
    "#                'alpha' : alpha, \n",
    "#                'num_hard' : num_hard, \n",
    "#                'optimiser' : optimiser,\n",
    "#                'lr' : lr,\n",
    "#                'emb_size' : emb_size\n",
    "#               }\n",
    "\n",
    "# with open(os.path.join(logdir, \"hyperparams.json\"), \"w\") as json_file:\n",
    "#     json.dump(hyperparams, json_file)\n",
    "\n",
    "def delete_older_model_files(filepath):\n",
    "    \n",
    "    model_dir = filepath.split(\"emb_model\")[0]\n",
    "    \n",
    "    # Get model files\n",
    "    model_files = os.listdir(model_dir)\n",
    "\n",
    "    # Get only the emb_model files\n",
    "    emb_model_files = [file for file in model_files if \"emb_model\" in file]\n",
    "    # Get the epoch nums of the emb_model_files\n",
    "    emb_model_files_epoch_nums = [int(file.split(\"-\")[1].split(\".h5\")[0]) for file in emb_model_files]\n",
    "\n",
    "    # Find all the snn model files\n",
    "    snn_model_files = [file for file in model_files if \"snn_model\" in file]\n",
    "\n",
    "    # Sort, get highest epoch num\n",
    "    emb_model_files_epoch_nums.sort()\n",
    "    highest_epoch_num = str(emb_model_files_epoch_nums[-1]).zfill(2)\n",
    "\n",
    "    # Filter the emb_model and snn_model file lists to remove the highest epoch number ones\n",
    "    emb_model_files_without_highest = [file for file in emb_model_files if highest_epoch_num not in file]\n",
    "    snn_model_files_without_highest = [file for file in snn_model_files if (\"-\" + highest_epoch_num + \"-\") not in file]\n",
    "\n",
    "    # Delete the non-highest model files from the subdir\n",
    "    if len(emb_model_files_without_highest) != 0:\n",
    "        print(\"Deleting previous best model file\")\n",
    "    for model_file_list in [emb_model_files_without_highest, snn_model_files_without_highest]:\n",
    "        for file in model_file_list:\n",
    "            os.remove(os.path.join(model_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-cache",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 369, 496) for input KerasTensor(type_spec=TensorSpec(shape=(None, 369, 496), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 369, 496) for input KerasTensor(type_spec=TensorSpec(shape=(None, 369, 496), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 369, 496) for input KerasTensor(type_spec=TensorSpec(shape=(None, 369, 496), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 369, 496) for input KerasTensor(type_spec=TensorSpec(shape=(None, 369, 496), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 369, 496) for input KerasTensor(type_spec=TensorSpec(shape=(None, 369, 496), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 369, 496) for input KerasTensor(type_spec=TensorSpec(shape=(None, 369, 496), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, None, None, None).\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# Make the model work over the two GPUs we have\n",
    "# num_gpus = get_num_gpus()\n",
    "# parallel_snn = multi_gpu_model(siamese_net, gpus = num_gpus)\n",
    "# batch_per_gpu = int(batch_size / num_gpus)\n",
    "\n",
    "siamese_net.compile(loss=triplet_loss, optimizer= optimiser_obj)\n",
    "\n",
    "siamese_history = siamese_net.fit(\n",
    "    data_generator(256),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "#     callbacks=callbacks, \n",
    "    workers = 0, \n",
    "#     validation_data = data_generator(batch_per_gpu, num_hard, split=\"test\"), \n",
    "#     validation_steps = val_steps)\n",
    ")\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "honest-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,alpha = create_hard_batch(0.2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "heard-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "dependent-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "\n",
    "arr.append(make_triplet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "documentary-reply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 496, 1)"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_anchor = \n",
    "# x_anchor = x_anchor.reshape(x_anchors.shape[0], x_anchor.shape[1], x_anchor.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "patent-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_anchor = x_anchor.reshape(1,x_anchor.shape[0], x_anchor.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "clinical-moisture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 369, 496, 1)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_anchor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "meaningful-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = embedding_model.predict(arr[0][0])\n",
    "two = embedding_model.predict(arr[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "available-nothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98758596"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dAP = np.linalg.norm(one - two)\n",
    "dAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "equipped-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9697467 , -1.2288555 , -0.35501355,  1.0466803 , -0.694643  ,\n",
       "       -3.1205397 , -1.2996997 ,  2.000761  , -2.33571   ,  1.1424414 ,\n",
       "       -0.7514131 , -0.47504073, -1.5201833 ,  0.3158146 , -1.9108859 ,\n",
       "       -1.7954549 , -1.4487057 , -2.5707815 , -0.85833174,  1.2824814 ,\n",
       "        0.871642  ,  1.2815903 , -1.9300065 ,  2.9488773 , -0.22975928,\n",
       "        2.5088716 ,  2.1847162 , -1.6413823 , -2.935345  , -1.0605464 ,\n",
       "        1.1033211 ,  1.619802  ], dtype=float32)"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
