{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input,Conv2D,Dense,Dropout,Lambda, GlobalAveragePooling2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform, he_uniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.utils import plot_model,normalize\n",
    "\n",
    "# from pylab import dist\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "derived-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../precalculated_files_mel/samplespace/\"\n",
    "\n",
    "# songs = list(Path(source_dir).glob('*.png'))\n",
    "img = Image.open(source_dir+\"000190.png\")\n",
    "width,height = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aging-salvation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 496)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(img)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opened-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_ind = pd.read_csv(\"../csvs/samplespace.csv\") \n",
    "len(tracks_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stable-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id           3400\n",
       "artist_name        3400\n",
       "artist_id          3400\n",
       "track_title        3400\n",
       "track_genre_top    3400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_ind.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assigned-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing outlier\n",
    "# tracks_ind[tracks_ind['artist_name']==\"Mastermind XS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "received-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_ind.loc[tracks_ind.artist_name=='Mastermind XS', \"artist_id\"] = 9169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "saving-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_ind[\"track_id\"] = [\"%06.0f\" % x for x in tracks_ind[\"track_id\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assured-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_imgs = np.zeros((len(tracks_ind), 369, 496))\n",
    "i = 0\n",
    "for index,row in tracks_ind.iterrows():\n",
    "    track_imgs[i] = np.asarray(Image.open(source_dir+tracks_ind.iloc[index][\"track_id\"]+\".png\"))/255\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_first_500().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "found-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_500():\n",
    "    tracks_set = track_imgs[:500]\n",
    "    tracks_set = tracks_set.reshape(tracks_set.shape[0], height, width, 1)\n",
    "    \n",
    "    return tracks_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "listed-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triplet():\n",
    "    x_anchor = np.zeros((height,width)) #Gonna have issues with image (369,496,1) not (369,496)\n",
    "    x_pos = np.zeros((height,width))\n",
    "    x_neg = np.zeros((height,width))\n",
    "    \n",
    "    triplet = np.zeros((3,height,width,1))\n",
    "    \n",
    "    rand_ind = random.randint(0, len(tracks_ind))\n",
    "    x_anchor = np.asarray(Image.open(source_dir+tracks_ind.iloc[rand_ind][\"track_id\"]+\".png\"))/255\n",
    "    x_anchor = track_imgs[rand_ind]\n",
    "    y = tracks_ind.loc[rand_ind][\"artist_id\"]\n",
    "    # y is an int32(artist_id is int) while track_id is str\n",
    "    \n",
    "    indices_for_pos = np.squeeze(np.where(tracks_ind['artist_id'] == y))   #selcting songs only belonging to same artist\n",
    "    indices_for_neg = np.squeeze(np.where(tracks_ind['artist_id'] != y))  #diff artists\n",
    "\n",
    "    x_pos_ind = tracks_ind.iloc[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]] #getting random pos id from df\n",
    "    x_neg_ind = tracks_ind.iloc[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]] #getting neg id from df\n",
    "#     print(x_pos_ind)\n",
    "    x_pos =  np.asarray(Image.open(source_dir+x_pos_ind[\"track_id\"]+\".png\"))/255\n",
    "    x_neg =  np.asarray(Image.open(source_dir+x_neg_ind[\"track_id\"]+\".png\"))/255\n",
    "#     x_pos = track_imgs[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]] #normalizing to 0-1\n",
    "#     x_neg =  track_imgs[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]]\n",
    "    \n",
    "    x_anchor = x_anchor.reshape(x_anchor.shape[0], x_anchor.shape[1],1)\n",
    "    x_pos = x_pos.reshape(x_pos.shape[0], x_pos.shape[1],1)\n",
    "    x_neg = x_neg.reshape(x_neg.shape[0], x_neg.shape[1],1)\n",
    "    \n",
    "    triplet[0] = x_anchor\n",
    "    triplet[1] = x_pos\n",
    "    triplet[2] = x_neg\n",
    "#     print(triplet.shape)\n",
    "    return triplet\n",
    "\n",
    "def create_hard_batch(alpha,batch_size=256):\n",
    "    x_anchors = np.zeros((batch_size, height,width,1))\n",
    "    x_positives = np.zeros((batch_size, height,width,1))\n",
    "    x_negatives = np.zeros((batch_size, height,width,1))\n",
    "    \n",
    "    ini_batch = [] \n",
    "    hard_batch = []\n",
    "    not_hard_batch = []\n",
    "    batch_losses = []\n",
    "    rand_batches = []\n",
    "    final_batch = np.zeros((batch_size,height,width,1))\n",
    "    \n",
    "    sample_size = 25 #512\n",
    "    \n",
    "    for i in range(0,sample_size):\n",
    "        ini_batch.append(make_triplet())\n",
    "        a_emb = embedding_model.predict(tf.expand_dims(ini_batch[i][0], axis=0))\n",
    "        p_emb = embedding_model.predict(tf.expand_dims(ini_batch[i][1], axis=0))\n",
    "        n_emb = embedding_model.predict(tf.expand_dims(ini_batch[i][2], axis=0))\n",
    "        \n",
    "        dAP = np.linalg.norm(a_emb -p_emb) #Should this be negated like in compute_prob func?\n",
    "        dAN = np.linalg.norm(a_emb- n_emb)\n",
    "        \n",
    "        if(dAN - dAP < alpha and dAN >= dAP):\n",
    "            hard_batch.append(ini_batch[i])\n",
    "        elif(dAN > dAP):\n",
    "            not_hard_batch.append(ini_batch[i])\n",
    "    \n",
    "    if(len(hard_batch)<batch_size): #batch prob 256\n",
    "        alpha += 0.05 # cuz we want up by 0.05 increments\n",
    "        remaining = batch_size-len(hard_batch) #later pick closest best hard\n",
    "        remaining = not_hard_batch[:remaining]\n",
    "    else:\n",
    "        remaining = not_hard_batch[0:0]\n",
    "        \n",
    "    final_batch = hard_batch+remaining\n",
    "    \n",
    "#     print(np.array(final_batch).shape)\n",
    "    \n",
    "    for i in range(0, len(final_batch)):\n",
    "        x_anchors[i] = final_batch[i][0]\n",
    "        x_positives[i] = final_batch[i][1]\n",
    "        x_negatives[i] = final_batch[i][2]\n",
    "        \n",
    "#     x_anchors =  x_anchors.reshape(x_anchors.shape[0], height, width, 1)\n",
    "#     x_positives =  x_positives.reshape(x_positives.shape[0], height, width, 1)\n",
    "#     x_negatives =  x_negatives.reshape(x_negatives.shape[0], height, width, 1)\n",
    "    triplets = [x_anchors, x_positives, x_negatives]\n",
    "        \n",
    "    return triplets,alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "endless-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = make_triplet()\n",
    "# x,alpha = create_hard_batch(0.2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "foster-fundamental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 369, 496, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "comfortable-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8808498 , -0.04060626,  0.17176443,  0.5432114 ,  0.9333533 ,\n",
       "         0.5537815 ,  0.87750113,  0.22218965, -0.02774212, -0.15773848,\n",
       "         0.6772737 , -0.6879555 , -0.9485324 ,  0.3735297 ,  0.7061977 ,\n",
       "        -0.08799163,  1.7050624 , -0.2762759 ,  0.47716436,  0.17354715,\n",
       "        -1.8845682 , -0.4174158 ,  0.24413651,  0.5322256 , -1.2216299 ,\n",
       "         1.2348878 , -0.1625027 ,  0.31828436, -0.423664  , -1.0195539 ,\n",
       "         0.09913108,  1.5147818 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.predict(tf.expand_dims(x[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "received-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "alpha = 0.2\n",
    "emb_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "western-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_model(input_shape=(height,width,1),emb_size=32): #inp shape has to be of form (height,width)\n",
    "    inputs = Input(input_shape);\n",
    "    x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(32, (5,5), padding=\"same\",  activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "#     x = Flatten()(x)\n",
    "    \n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     Output = Dense(32, activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    outputs = Dense(emb_size,kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(pooledOutput)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "logical-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (height,width,1)\n",
    "# print(input_shape)\n",
    "def SNN(embedding_model):\n",
    "    input_anchor = Input(shape=input_shape)\n",
    "    input_positive = Input(shape=input_shape)\n",
    "    input_negative = Input(shape=input_shape)\n",
    "    \n",
    "    embedding_anchor = embedding_model(input_anchor)\n",
    "    embedding_positive = embedding_model(input_positive)\n",
    "    embedding_negative = embedding_model(input_negative)\n",
    "    \n",
    "    output = tf.keras.layers.concatenate([embedding_anchor,embedding_positive, embedding_negative],axis=1) \n",
    "    # Weird thing where only tf.keras works not Concatenate\n",
    "    \n",
    "    siamese_net = Model([input_anchor, input_positive, input_negative], output)\n",
    "    \n",
    "    siamese_net.summary()\n",
    "#     plot_model(siamese_net,show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rapid-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true,y_pred):\n",
    "#     print(y_pred.shape[0])\n",
    "    anchor, pos, neg = y_pred[:,:emb_size],y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size:]\n",
    "    dAP = tf.norm(anchor-pos)\n",
    "    dAN = tf.norm(anchor-neg)\n",
    "    return tf.maximum(pos - neg + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "polish-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_generator(batch_size=256, alpha=0.2):\n",
    "#     while True:\n",
    "#         x,alpha = create_hard_batch(alpha,batch_size)\n",
    "#         y = np.zeros((batch_size, 3*emb_size))\n",
    "#         yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "racial-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPY PASTE from https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352\n",
    "# Well not really updated but func is genrally same\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings \n",
    "        X : tensor of shape (m,h,w,1) containing pics to evaluate => m is 500\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2) # => 500C2 => like 124,000\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all imgs with current embedding network\n",
    "    embeddings = embedding_model.predict(X)\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    # For each img in the evaluation set\n",
    "    for i in range(m):\n",
    "            # Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                # compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                    #print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tSAME\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                    #print(\"{3}:{0} vs {1} : {2}\\tDIFF\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                k += 1\n",
    "    return probs, y\n",
    "\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    return fpr, tpr, thresholds,auc\n",
    "\n",
    "def draw_roc(fpr, tpr,thresholds, auc):\n",
    "    #find threshold\n",
    "    targetfpr=1e-3\n",
    "    _, idx = find_nearest(fpr,targetfpr)\n",
    "    threshold = thresholds[idx]\n",
    "    recall = tpr[idx]\n",
    "    \n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold) ))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "\n",
    "def draw_interdist(network, epochs,test_set):\n",
    "    interdist = compute_interdist(network,test_set)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(num_classes):\n",
    "        data.append(np.delete(interdist[i,:],[i]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Evaluating embeddings distance from each other after {0} epochs'.format(epochs))\n",
    "    ax.set_ylim([0,3])\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Distance')\n",
    "    ax.boxplot(data,showfliers=False,showbox=True)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs,np.arange(num_classes))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def compute_interdist(network,test_set):\n",
    "    '''\n",
    "    Computes sum of distances between all classes embeddings on our reference test image: \n",
    "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
    "        A good model should have a large distance between all theses embeddings\n",
    "        \n",
    "    Returns:\n",
    "        array of shape (num_classes,num_classes) \n",
    "    '''\n",
    "    res = np.zeros((num_classes,num_classes))\n",
    "    \n",
    "    ref_images = np.zeros((num_classes, height,width, 1))\n",
    "    \n",
    "    #generates embeddings for reference images\n",
    "    for i in range(num_classes):\n",
    "        ref_images[i,:,:,:] = test_set_imgs[i,:,:,:]\n",
    "    \n",
    "    ref_embeddings = network.predict(ref_images)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "#             res[i,j] = dist(ref_embeddings[i],ref_embeddings[j]) \n",
    "            # dist func doesnt work\n",
    "            res[i,j] = compute_dist(ref_embeddings[i],ref_embeddings[j]) #Should it be negative?\n",
    "    return res\n",
    "\n",
    "def DrawTestImage(network, images, refidx=0):\n",
    "    '''\n",
    "    Evaluate some pictures vs some samples in the test set\n",
    "        image must be of shape(1,w,h,c)\n",
    "    \n",
    "    Returns\n",
    "        scores : result of the similarity scores with the basic images => (N)\n",
    "    \n",
    "    '''\n",
    "    nbimages = images.shape[0]\n",
    "    \n",
    "    print(\"Predicting embeding\")\n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    \n",
    "    print(\"Computing dist\")\n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((num_classes,height,width,1))\n",
    "    for i in range(num_classes):\n",
    "        images_at_this_index_are_of_class_i = np.squeeze(np.where(test_set.artist_id == i))\n",
    "#         ref_images[i,:] = x_test[images_at_this_index_are_of_class_i[refidx]]\n",
    "        ref_images[i,:,:,:] = test_set_imgs[images_at_this_index_are_of_class_i[refidx]] #prob will be broken\n",
    "        \n",
    "        \n",
    "    ref_embedings = network.predict(ref_images)\n",
    "            \n",
    "    for i in range(nbimages):\n",
    "        # Prepare the figure\n",
    "        fig=plt.figure(figsize=(16,2))\n",
    "        subplot = fig.add_subplot(1,num_classes+1,1)\n",
    "        plt.axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        # Draw this image    \n",
    "        plt.imshow(np.reshape(images[i], (width, height)),vmin=0, vmax=1,cmap='Greys') #maybe (height,width)\n",
    "        subplot.title.set_text(\"Test image\")\n",
    "            \n",
    "        for ref in range(num_classes):\n",
    "            #Compute distance between this images and references\n",
    "            dist = compute_dist(image_embedings[i,:],ref_embedings[ref,:])\n",
    "            #Draw\n",
    "            subplot = fig.add_subplot(1,num_classes+1,plotidx)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(np.reshape(ref_images[ref, :], (width, height)),vmin=0, vmax=1,cmap='Greys')\n",
    "            subplot.title.set_text((\"Class {0}\\n{1:.3e}\".format(ref,dist)))\n",
    "            plotidx += 1\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(embedding_model, epochs=0):\n",
    "    test_set_imgs = np.zeros((500,height,width))\n",
    "    test_set = get_test_set(500)\n",
    "    i = 0\n",
    "    for index,rowdata  in test_set.iterrows():\n",
    "        test_set_imgs[i] = track_imgs[index]\n",
    "        i+=1\n",
    "    test_set_imgs = test_set_imgs.reshape(test_set.shape[0], height, width, 1)\n",
    "    \n",
    "    probs, yprob = compute_probs(embedding_model, test_set_imgs, test_set[:500].artist_id.array)\n",
    "    fpr, tpr, thresholds, auc = compute_metrics(probs,yprob)\n",
    "    draw_roc(fpr, tpr, thresholds, auc)\n",
    "    draw_interdist(embedding_model, epochs,test_set)\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         DrawTestImage(embedding_model, np.expand_dims(test_set_imgs[i],axis=0)) \n",
    "#Maybe later cuz gotta fix abv func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fiscal-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set(n_samples=500): #Equally get each class atleast 1\n",
    "    test_set2 = tracks_ind.groupby(\"artist_id\").sample(n=2) \n",
    "    first_half = test_set2[test_set2.duplicated(subset='artist_id', keep=\"first\")] #get first copy 354 one song \n",
    "    second_half = test_set2[test_set2.duplicated(subset='artist_id', keep=\"last\")] #get last half 146 (500-354)\n",
    "    full_fhun = pd.concat([first_half, second_half.sample(n_samples - len(first_half))])\n",
    "    return full_fhun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "crucial-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def generate_prototypes(x_data, y_data, embedding_model):\\n    classes = np.unique(y_data)\\n    prototypes = {}\\n\\n    for c in classes:\\n        #c = classes[0]\\n        # Find all images of the chosen test class\\n        locations_of_c = np.where(y_data == c)[0]\\n\\n        imgs_of_c = x_data[locations_of_c]\\n\\n        imgs_of_c_embeddings = embedding_model.predict(imgs_of_c)\\n\\n        # Get the median of the embeddings to generate a prototype for the class (reshaping for PCA)\\n        prototype_for_c = np.median(imgs_of_c_embeddings, axis = 0).reshape(1, -1)\\n        # Add it to the prototype dict\\n        prototypes[c] = prototype_for_c\\n        \\n    return prototypes\\n         \\ndef test_one_shot_prototypes(network, sample_embeddings):\\n    distances_from_img_to_test_against = []\\n    # As the img to test against is in index 0, we compare distances between img@0 and all others\\n    for i in range(1, len(sample_embeddings)):\\n        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\\n    # As the correct img will be at distances_from_img_to_test_against index 0 (sample_imgs index 1),\\n    # If the smallest distance in distances_from_img_to_test_against is at index 0, \\n    # we know the one shot test got the right answer\\n    is_min = distances_from_img_to_test_against[0] == min(distances_from_img_to_test_against)\\n    is_max = distances_from_img_to_test_against[0] == max(distances_from_img_to_test_against)\\n    return int(is_min and not is_max)\\n    \\ndef n_way_accuracy_prototypes(n_val, n_way, network):\\n    num_correct = 0\\n    \\n    for val_step in range(n_val):\\n        num_correct += load_one_shot_test_batch_prototypes(n_way, network)\\n        \\n    accuracy = num_correct / n_val * 100\\n        \\n    return accuracy\\n\\ndef load_one_shot_test_batch_prototypes(n_way, network):\\n    \\n    labels = np.unique(y_test)\\n    # Reduce the label set down from size n_classes to n_samples \\n    labels = np.random.choice(labels, size = n_way, replace = False)\\n\\n    # Choose a class as the test image\\n    label = random.choice(labels)\\n    # Find all images of the chosen test class\\n    imgs_of_label = np.where(y_test == label)[0]\\n\\n    # Randomly select a test image of the selected class, return it's index\\n    img_of_label_idx = random.choice(imgs_of_label)\\n\\n    # Expand the array at the selected indexes into useable images\\n    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\\n    \\n    sample_embeddings = []\\n    # Get the anchor image embedding\\n    anchor_prototype = network.predict(img_of_label)\\n    sample_embeddings.append(anchor_prototype)\\n    \\n    # Get the prototype embedding for the positive class\\n    positive_prototype = prototypes[label]\\n \\n    sample_embeddings.append(positive_prototype)\\n    \\n    # Get the negative prototype embeddings\\n    # Remove the selected test class from the list of labels based on it's index \\n    label_idx_in_labels = np.where(labels == label)[0]\\n    other_labels = np.delete(labels, label_idx_in_labels)\\n    \\n    # Get the embedding for each of the remaining negatives\\n    for other_label in other_labels:\\n        negative_prototype = prototypes[other_label]\\n        sample_embeddings.append(negative_prototype)\\n                \\n    correct = test_one_shot_prototypes(network, sample_embeddings)\\n\\n    return correct\\n\\n\\ndef visualise_n_way_prototypes(n_samples, network):\\n    labels = np.unique(y_test)\\n    # Reduce the label set down from size n_classes to n_samples \\n    labels = np.random.choice(labels, size = n_samples, replace = False)\\n\\n    # Choose a class as the test image\\n    label = random.choice(labels)\\n    # Find all images of the chosen test class\\n    imgs_of_label = np.where(y_test == label)[0]\\n\\n    # Randomly select a test image of the selected class, return it's index\\n    img_of_label_idx = random.choice(imgs_of_label)\\n\\n    # Get another image idx that we know is of the test class for the sample set\\n    label_sample_img_idx = random.choice(imgs_of_label)\\n\\n    # Expand the array at the selected indexes into useable images\\n    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\\n    label_sample_img = np.expand_dims(x_test[label_sample_img_idx],axis=0)\\n    \\n    # Make the first img in the sample set the chosen test image, the second the other image\\n    sample_imgs = np.empty((0, x_test_w_h))\\n    sample_imgs = np.append(sample_imgs, img_of_label, axis=0)\\n    sample_imgs = np.append(sample_imgs, label_sample_img, axis=0)\\n    \\n    sample_embeddings = []\\n    \\n    # Get the anchor embedding image\\n    anchor_prototype = network.predict(img_of_label)\\n    sample_embeddings.append(anchor_prototype)\\n    \\n    # Get the prototype embedding for the positive class\\n    positive_prototype = prototypes[label]\\n    sample_embeddings.append(positive_prototype)\\n\\n    # Get the negative prototype embeddings\\n    # Remove the selected test class from the list of labels based on it's index \\n    label_idx_in_labels = np.where(labels == label)[0]\\n    other_labels = np.delete(labels, label_idx_in_labels)\\n    # Get the embedding for each of the remaining negatives\\n    for other_label in other_labels:\\n        negative_prototype = prototypes[other_label]\\n        sample_embeddings.append(negative_prototype)\\n        \\n        # Find all images of the other class\\n        imgs_of_other_label = np.where(y_test == other_label)[0]\\n        # Randomly select an image of the selected class, return it's index\\n        another_sample_img_idx = random.choice(imgs_of_other_label)\\n        # Expand the array at the selected index into useable images\\n        another_sample_img = np.expand_dims(x_test[another_sample_img_idx],axis=0)\\n        # Add the image to the support set\\n        sample_imgs = np.append(sample_imgs, another_sample_img, axis=0)\\n    \\n    distances_from_img_to_test_against = []\\n    \\n    # As the img to test against is in index 0, we compare distances between img@0 and all others\\n    for i in range(1, len(sample_embeddings)):\\n        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\\n        \\n    # + 1 as distances_from_img_to_test_against doesn't include the test image\\n    min_index = distances_from_img_to_test_against.index(min(distances_from_img_to_test_against)) + 1\\n    \\n    return sample_imgs, min_index\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More fns unused as to be adapted\n",
    "\n",
    "'''def generate_prototypes(x_data, y_data, embedding_model):\n",
    "    classes = np.unique(y_data)\n",
    "    prototypes = {}\n",
    "\n",
    "    for c in classes:\n",
    "        #c = classes[0]\n",
    "        # Find all images of the chosen test class\n",
    "        locations_of_c = np.where(y_data == c)[0]\n",
    "\n",
    "        imgs_of_c = x_data[locations_of_c]\n",
    "\n",
    "        imgs_of_c_embeddings = embedding_model.predict(imgs_of_c)\n",
    "\n",
    "        # Get the median of the embeddings to generate a prototype for the class (reshaping for PCA)\n",
    "        prototype_for_c = np.median(imgs_of_c_embeddings, axis = 0).reshape(1, -1)\n",
    "        # Add it to the prototype dict\n",
    "        prototypes[c] = prototype_for_c\n",
    "        \n",
    "    return prototypes\n",
    "         \n",
    "def test_one_shot_prototypes(network, sample_embeddings):\n",
    "    distances_from_img_to_test_against = []\n",
    "    # As the img to test against is in index 0, we compare distances between img@0 and all others\n",
    "    for i in range(1, len(sample_embeddings)):\n",
    "        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\n",
    "    # As the correct img will be at distances_from_img_to_test_against index 0 (sample_imgs index 1),\n",
    "    # If the smallest distance in distances_from_img_to_test_against is at index 0, \n",
    "    # we know the one shot test got the right answer\n",
    "    is_min = distances_from_img_to_test_against[0] == min(distances_from_img_to_test_against)\n",
    "    is_max = distances_from_img_to_test_against[0] == max(distances_from_img_to_test_against)\n",
    "    return int(is_min and not is_max)\n",
    "    \n",
    "def n_way_accuracy_prototypes(n_val, n_way, network):\n",
    "    num_correct = 0\n",
    "    \n",
    "    for val_step in range(n_val):\n",
    "        num_correct += load_one_shot_test_batch_prototypes(n_way, network)\n",
    "        \n",
    "    accuracy = num_correct / n_val * 100\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "def load_one_shot_test_batch_prototypes(n_way, network):\n",
    "    \n",
    "    labels = np.unique(y_test)\n",
    "    # Reduce the label set down from size n_classes to n_samples \n",
    "    labels = np.random.choice(labels, size = n_way, replace = False)\n",
    "\n",
    "    # Choose a class as the test image\n",
    "    label = random.choice(labels)\n",
    "    # Find all images of the chosen test class\n",
    "    imgs_of_label = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select a test image of the selected class, return it's index\n",
    "    img_of_label_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Expand the array at the selected indexes into useable images\n",
    "    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\n",
    "    \n",
    "    sample_embeddings = []\n",
    "    # Get the anchor image embedding\n",
    "    anchor_prototype = network.predict(img_of_label)\n",
    "    sample_embeddings.append(anchor_prototype)\n",
    "    \n",
    "    # Get the prototype embedding for the positive class\n",
    "    positive_prototype = prototypes[label]\n",
    " \n",
    "    sample_embeddings.append(positive_prototype)\n",
    "    \n",
    "    # Get the negative prototype embeddings\n",
    "    # Remove the selected test class from the list of labels based on it's index \n",
    "    label_idx_in_labels = np.where(labels == label)[0]\n",
    "    other_labels = np.delete(labels, label_idx_in_labels)\n",
    "    \n",
    "    # Get the embedding for each of the remaining negatives\n",
    "    for other_label in other_labels:\n",
    "        negative_prototype = prototypes[other_label]\n",
    "        sample_embeddings.append(negative_prototype)\n",
    "                \n",
    "    correct = test_one_shot_prototypes(network, sample_embeddings)\n",
    "\n",
    "    return correct\n",
    "\n",
    "\n",
    "def visualise_n_way_prototypes(n_samples, network):\n",
    "    labels = np.unique(y_test)\n",
    "    # Reduce the label set down from size n_classes to n_samples \n",
    "    labels = np.random.choice(labels, size = n_samples, replace = False)\n",
    "\n",
    "    # Choose a class as the test image\n",
    "    label = random.choice(labels)\n",
    "    # Find all images of the chosen test class\n",
    "    imgs_of_label = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select a test image of the selected class, return it's index\n",
    "    img_of_label_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Get another image idx that we know is of the test class for the sample set\n",
    "    label_sample_img_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Expand the array at the selected indexes into useable images\n",
    "    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\n",
    "    label_sample_img = np.expand_dims(x_test[label_sample_img_idx],axis=0)\n",
    "    \n",
    "    # Make the first img in the sample set the chosen test image, the second the other image\n",
    "    sample_imgs = np.empty((0, x_test_w_h))\n",
    "    sample_imgs = np.append(sample_imgs, img_of_label, axis=0)\n",
    "    sample_imgs = np.append(sample_imgs, label_sample_img, axis=0)\n",
    "    \n",
    "    sample_embeddings = []\n",
    "    \n",
    "    # Get the anchor embedding image\n",
    "    anchor_prototype = network.predict(img_of_label)\n",
    "    sample_embeddings.append(anchor_prototype)\n",
    "    \n",
    "    # Get the prototype embedding for the positive class\n",
    "    positive_prototype = prototypes[label]\n",
    "    sample_embeddings.append(positive_prototype)\n",
    "\n",
    "    # Get the negative prototype embeddings\n",
    "    # Remove the selected test class from the list of labels based on it's index \n",
    "    label_idx_in_labels = np.where(labels == label)[0]\n",
    "    other_labels = np.delete(labels, label_idx_in_labels)\n",
    "    # Get the embedding for each of the remaining negatives\n",
    "    for other_label in other_labels:\n",
    "        negative_prototype = prototypes[other_label]\n",
    "        sample_embeddings.append(negative_prototype)\n",
    "        \n",
    "        # Find all images of the other class\n",
    "        imgs_of_other_label = np.where(y_test == other_label)[0]\n",
    "        # Randomly select an image of the selected class, return it's index\n",
    "        another_sample_img_idx = random.choice(imgs_of_other_label)\n",
    "        # Expand the array at the selected index into useable images\n",
    "        another_sample_img = np.expand_dims(x_test[another_sample_img_idx],axis=0)\n",
    "        # Add the image to the support set\n",
    "        sample_imgs = np.append(sample_imgs, another_sample_img, axis=0)\n",
    "    \n",
    "    distances_from_img_to_test_against = []\n",
    "    \n",
    "    # As the img to test against is in index 0, we compare distances between img@0 and all others\n",
    "    for i in range(1, len(sample_embeddings)):\n",
    "        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\n",
    "        \n",
    "    # + 1 as distances_from_img_to_test_against doesn't include the test image\n",
    "    min_index = distances_from_img_to_test_against.index(min(distances_from_img_to_test_against)) + 1\n",
    "    \n",
    "    return sample_imgs, min_index'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fatty-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding model... \n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 369, 496, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 369, 496, 16)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 184, 248, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 184, 248, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 184, 248, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 92, 124, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 92, 124, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 90, 122, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 45, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 45, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 43, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 107,680\n",
      "Trainable params: 107,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Generating SNN... \n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 369, 496, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 369, 496, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 369, 496, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 32)           107680      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           model[0][0]                      \n",
      "                                                                 model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "==================================================================================================\n",
      "Total params: 107,680\n",
      "Trainable params: 107,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vignesh\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model without training for a baseline...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 15 #100\n",
    "steps_per_epoch = int(tracks_ind.shape[0]/batch_size)\n",
    "# val_steps = int(x_test.shape[0]/batch_size)\n",
    "alpha = 0.2\n",
    "num_hard = int(batch_size * 0.5) # Number of semi-hard triplet examples in the batch\n",
    "lr = 0.00006\n",
    "optimiser = 'Adam'\n",
    "emb_size = 32 # 10 in mnist\n",
    "input_size = (369,496,1)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # Create the embedding model\n",
    "    print(\"Generating embedding model... \\n\")\n",
    "    embedding_model = make_embedding_model(emb_size=emb_size) #maybe dec input size (369,496) \n",
    "    \n",
    "    print(\"\\nGenerating SNN... \\n\")\n",
    "    # Create the SNN\n",
    "    siamese_net = SNN(embedding_model)\n",
    "    # Compile the SNN\n",
    "    optimiser_obj = Adam(lr = lr)\n",
    "    siamese_net.compile(loss=triplet_loss, optimizer= optimiser_obj)\n",
    "    \n",
    "    # Store visualisations of the embeddings using PCA for display next to \"after training\" for comparisons\n",
    "    num_vis = 500 # Take only the first num_vis elements of the test set to visualise\n",
    "    embeddings_before_train = embedding_model.predict(get_first_500())\n",
    "    pca = PCA(n_components=2)\n",
    "    decomposed_embeddings_before = pca.fit_transform(embeddings_before_train)\n",
    "\n",
    "print(\"\\nEvaluating the model without training for a baseline...\\n\")\n",
    "# evaluate(embedding_model)\n",
    "\n",
    "#### DO CALLBACKS LATER\n",
    "\n",
    "# Save model configs to JSON\n",
    "# model_json = siamese_net.to_json()\n",
    "# with open(os.path.join(logdir, \"siamese_config.json\"), \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "#     json_file.close()\n",
    "    \n",
    "# model_json = embedding_model.to_json()\n",
    "# with open(os.path.join(logdir, \"embedding_config.json\"), \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "#     json_file.close()\n",
    "    \n",
    "# hyperparams = {'batch_size' : batch_size,\n",
    "#               'epochs' : epochs, \n",
    "#                'steps_per_epoch' : steps_per_epoch, \n",
    "#                'val_steps' : val_steps, \n",
    "#                'alpha' : alpha, \n",
    "#                'num_hard' : num_hard, \n",
    "#                'optimiser' : optimiser,\n",
    "#                'lr' : lr,\n",
    "#                'emb_size' : emb_size\n",
    "#               }\n",
    "\n",
    "# with open(os.path.join(logdir, \"hyperparams.json\"), \"w\") as json_file:\n",
    "#     json.dump(hyperparams, json_file)\n",
    "\n",
    "def delete_older_model_files(filepath):\n",
    "    \n",
    "    model_dir = filepath.split(\"emb_model\")[0]\n",
    "    \n",
    "    # Get model files\n",
    "    model_files = os.listdir(model_dir)\n",
    "\n",
    "    # Get only the emb_model files\n",
    "    emb_model_files = [file for file in model_files if \"emb_model\" in file]\n",
    "    # Get the epoch nums of the emb_model_files\n",
    "    emb_model_files_epoch_nums = [int(file.split(\"-\")[1].split(\".h5\")[0]) for file in emb_model_files]\n",
    "\n",
    "    # Find all the snn model files\n",
    "    snn_model_files = [file for file in model_files if \"snn_model\" in file]\n",
    "\n",
    "    # Sort, get highest epoch num\n",
    "    emb_model_files_epoch_nums.sort()\n",
    "    highest_epoch_num = str(emb_model_files_epoch_nums[-1]).zfill(2)\n",
    "\n",
    "    # Filter the emb_model and snn_model file lists to remove the highest epoch number ones\n",
    "    emb_model_files_without_highest = [file for file in emb_model_files if highest_epoch_num not in file]\n",
    "    snn_model_files_without_highest = [file for file in snn_model_files if (\"-\" + highest_epoch_num + \"-\") not in file]\n",
    "\n",
    "    # Delete the non-highest model files from the subdir\n",
    "    if len(emb_model_files_without_highest) != 0:\n",
    "        print(\"Deleting previous best model file\")\n",
    "    for model_file_list in [emb_model_files_without_highest, snn_model_files_without_highest]:\n",
    "        for file in model_file_list:\n",
    "            os.remove(os.path.join(model_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "Epoch 1/15\n",
      " 1/10 [==>...........................] - ETA: 3:07 - loss: 0.8844"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# Make the model work over the two GPUs we have\n",
    "# num_gpus = get_num_gpus()\n",
    "# parallel_snn = multi_gpu_model(siamese_net, gpus = num_gpus)\n",
    "# batch_per_gpu = int(batch_size / num_gpus)\n",
    "siamese_net.compile(loss=triplet_loss, optimizer= optimiser_obj)\n",
    "\n",
    "n_iter = 1000\n",
    "n_iteration = 0\n",
    "evaluate_every = 100\n",
    "t_start = time.time()\n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "    triplets = create_hard_batch(256)\n",
    "    loss = siamese_net.train_on_batch(triplets, None)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        probs,yprob = compute_probs(embedding_model,test_set_imgs, test_set[:500].artist_id.array)\n",
    "        #fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "        #draw_roc(fpr, tpr)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547ab43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "dependent-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "\n",
    "arr.append(make_triplet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "patent-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_anchor = x_anchor.reshape(1,x_anchor.shape[0], x_anchor.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "clinical-moisture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 369, 496, 1)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_anchor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "meaningful-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = embedding_model.predict(arr[0][0])\n",
    "two = embedding_model.predict(arr[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
