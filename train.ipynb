{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "from tensorflow.keras.layers import Input,Conv2D,Dense,Dropout,Lambda, GlobalAveragePooling2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform, he_uniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.utils import plot_model,normalize\n",
    "\n",
    "# from pylab import dist\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "swedish-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sublime-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 369\n",
    "width = 496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unexpected-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.default_rng(2021)\n",
    "sample_indices = np.random.randint(0,y_train.size, size=500) # Setting fixed indices for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "found-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_500():\n",
    "    return x_train[sample_indices]\n",
    "#     return x_train[:500], y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beginning-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_anc = x_train[sample_indices[1]]  \n",
    "y = y_train[sample_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "listed-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triplet(index):\n",
    "    triplet = np.zeros((3,height,width,1))\n",
    "    \n",
    "    x_anchor = x_train[index]\n",
    "    y = y_train[index]\n",
    "    \n",
    "    pos_inds = np.where(y_train==y)[0] #Getting same artist song\n",
    "    pos_inds = np.delete(pos_inds,np.where(pos_inds==index))\n",
    "    pos_sel = np.random.choice(pos_inds,1) \n",
    "    \n",
    "    neg_inds = np.where(y_train!=y)[0] #Getting diff artist song\n",
    "    neg_sel = np.random.choice(neg_inds,1) \n",
    "\n",
    "    x_pos =  x_train[pos_sel]\n",
    "    x_neg =  x_train[neg_sel]\n",
    "    \n",
    "    triplet[0] = x_anchor\n",
    "    triplet[1] = x_pos\n",
    "    triplet[2] = x_neg\n",
    "#     print(triplet.shape)\n",
    "    return triplet\n",
    "\n",
    "def create_hard_batch(alpha,batch_size=256):\n",
    "    ini_batch = [] \n",
    "    hard_indices = []\n",
    "\n",
    "    sample_size = batch_size #512\n",
    "    \n",
    "    sample_indices = np.random.randint(0,y_train.size, size=sample_size)\n",
    "    \n",
    "    for i in range(0,sample_size):\n",
    "        ini_batch.append(make_triplet(sample_indices[i]))\n",
    "        a_emb = embedding_model.predict(tf.expand_dims(ini_batch[i][0], axis=0))\n",
    "        p_emb = embedding_model.predict(tf.expand_dims(ini_batch[i][1], axis=0))\n",
    "        n_emb = embedding_model.predict(tf.expand_dims(ini_batch[i][2], axis=0))\n",
    "        \n",
    "        dAP = np.linalg.norm(a_emb -p_emb) #Should this be negated like in compute_prob func?\n",
    "        dAN = np.linalg.norm(a_emb- n_emb)\n",
    "        \n",
    "        if(dAN - dAP < alpha and dAN >= dAP):\n",
    "            hard_indices.append(i) # Maintaining record of hard indices so can be added later\n",
    "            \n",
    "    x_anchors = np.zeros((len(hard_indices), height,width,1))\n",
    "    x_positives = np.zeros((len(hard_indices), height,width,1))\n",
    "    x_negatives = np.zeros((len(hard_indices), height,width,1))\n",
    "    \n",
    "#     print(np.array(final_batch).shape)\n",
    "    \n",
    "    j=0\n",
    "    \n",
    "    for ind in hard_indices:\n",
    "        x_anchors[j] = ini_batch[ind][0]\n",
    "        x_positives[j] = ini_batch[ind][1]\n",
    "        x_negatives[j] = ini_batch[ind][2]\n",
    "        j+=1\n",
    "        \n",
    "#     x_anchors =  x_anchors.reshape(x_anchors.shape[0], height, width, 1)\n",
    "#     x_positives =  x_positives.reshape(x_positives.shape[0], height, width, 1)\n",
    "#     x_negatives =  x_negatives.reshape(x_negatives.shape[0], height, width, 1)\n",
    "    triplets = [x_anchors, x_positives, x_negatives]\n",
    "        \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "endless-headquarters",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-62bddbb5d5ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# x = make_triplet()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_hard_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#EXPONENTIAL TIME dont keep 1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-74721237a747>\u001b[0m in \u001b[0;36mcreate_hard_batch\u001b[1;34m(alpha, batch_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mini_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_triplet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0ma_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mini_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mp_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mini_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mn_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mini_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "# x = make_triplet()\n",
    "t = time.time()\n",
    "x = create_hard_batch(0.2,256) #EXPONENTIAL TIME dont keep 1024\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "comfortable-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model.predict(tf.expand_dims(x_train[3], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "received-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "alpha = 0.2\n",
    "emb_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "western-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_model(input_shape=(height,width,1),emb_size=32): #inp shape has to be of form (height,width)\n",
    "    inputs = Input(input_shape);\n",
    "    x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(32, (5,5), padding=\"same\",  activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3),   activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "#     x = Flatten()(x)\n",
    "    \n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     Output = Dense(32, activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    outputs = Dense(emb_size,kernel_regularizer=l2(1e-3),kernel_initializer='he_uniform')(pooledOutput)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "logical-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (height,width,1)\n",
    "# print(input_shape)\n",
    "def SNN(embedding_model):\n",
    "    input_anchor = Input(shape=input_shape)\n",
    "    input_positive = Input(shape=input_shape)\n",
    "    input_negative = Input(shape=input_shape)\n",
    "    \n",
    "    embedding_anchor = embedding_model(input_anchor)\n",
    "    embedding_positive = embedding_model(input_positive)\n",
    "    embedding_negative = embedding_model(input_negative)\n",
    "    \n",
    "    output = tf.keras.layers.concatenate([embedding_anchor,embedding_positive, embedding_negative],axis=1) \n",
    "    # Weird thing where only tf.keras works not Concatenate\n",
    "    \n",
    "    siamese_net = Model([input_anchor, input_positive, input_negative], output)\n",
    "    \n",
    "    siamese_net.summary()\n",
    "#     plot_model(siamese_net,show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rapid-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true,y_pred):\n",
    "#     print(y_pred.shape[0])\n",
    "    anchor, pos, neg = y_pred[:,:emb_size],y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size:]\n",
    "    dAP = tf.norm(anchor-pos)\n",
    "    dAN = tf.norm(anchor-neg)\n",
    "    return tf.maximum(pos - neg + alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "polish-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_generator(batch_size=256, alpha=0.2):\n",
    "#     while True:\n",
    "#         x,alpha = create_hard_batch(alpha,batch_size)\n",
    "#         y = np.zeros((batch_size, 3*emb_size))\n",
    "#         yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "racial-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPY PASTE from https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352\n",
    "# Well not really updated but func is genrally same\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings \n",
    "        X : tensor of shape (m,h,w,1) containing pics to evaluate => m is 500\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2) # => 500C2 => like 124,000\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all imgs with current embedding network\n",
    "    embeddings = embedding_model.predict(X)\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    # For each img in the evaluation set\n",
    "    for i in range(m):\n",
    "            # Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                # compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                    #print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tSAME\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                    #print(\"{3}:{0} vs {1} : {2}\\tDIFF\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                k += 1\n",
    "    return probs, y\n",
    "\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    return fpr, tpr, thresholds,auc\n",
    "\n",
    "def draw_roc(fpr, tpr,thresholds, auc):\n",
    "    #find threshold\n",
    "    targetfpr=1e-3\n",
    "    _, idx = find_nearest(fpr,targetfpr)\n",
    "    threshold = thresholds[idx]\n",
    "    recall = tpr[idx]\n",
    "    \n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold) ))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "\n",
    "def draw_interdist(network, epochs):\n",
    "    interdist = compute_interdist(network)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(num_classes):\n",
    "        data.append(np.delete(interdist[i,:],[i]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Evaluating embeddings distance from each other after {0} epochs'.format(epochs))\n",
    "    ax.set_ylim([0,3])\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Distance')\n",
    "    ax.boxplot(data,showfliers=False,showbox=True)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs,np.arange(num_classes))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def compute_interdist(network):\n",
    "    '''\n",
    "    Computes sum of distances between all classes embeddings on our reference test image: \n",
    "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
    "        A good model should have a large distance between all theses embeddings\n",
    "        \n",
    "    Returns:\n",
    "        array of shape (num_classes,num_classes) \n",
    "    '''\n",
    "    res = np.zeros((num_classes,num_classes))\n",
    "    \n",
    "    ref_images = np.zeros((num_classes, height,width, 1))\n",
    "    \n",
    "    #generates embeddings for reference images\n",
    "    for i in range(6):\n",
    "        ref_images[i,:,:,:] = x_train[i*6,:,:,:]\n",
    "    \n",
    "    ref_embeddings = network.predict(ref_images)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            res[i,j] = compute_dist(ref_embeddings[i],ref_embeddings[j]) #Should it be negative?\n",
    "    return res\n",
    "\n",
    "\n",
    "def evaluate(embedding_model, epochs=0):\n",
    "    probs, yprob = compute_probs(embedding_model, x_test[:100], y_test[:100])\n",
    "    fpr, tpr, thresholds, auc = compute_metrics(probs,yprob)\n",
    "    draw_roc(fpr, tpr, thresholds, auc)\n",
    "    draw_interdist(embedding_model, epochs)\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         DrawTestImage(embedding_model, np.expand_dims(x_train[i],axis=0)) \n",
    "#Maybe later cuz gotta fix abv func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "crucial-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def generate_prototypes(x_data, y_data, embedding_model):\\n    classes = np.unique(y_data)\\n    prototypes = {}\\n\\n    for c in classes:\\n        #c = classes[0]\\n        # Find all images of the chosen test class\\n        locations_of_c = np.where(y_data == c)[0]\\n\\n        imgs_of_c = x_data[locations_of_c]\\n\\n        imgs_of_c_embeddings = embedding_model.predict(imgs_of_c)\\n\\n        # Get the median of the embeddings to generate a prototype for the class (reshaping for PCA)\\n        prototype_for_c = np.median(imgs_of_c_embeddings, axis = 0).reshape(1, -1)\\n        # Add it to the prototype dict\\n        prototypes[c] = prototype_for_c\\n        \\n    return prototypes\\n         \\ndef test_one_shot_prototypes(network, sample_embeddings):\\n    distances_from_img_to_test_against = []\\n    # As the img to test against is in index 0, we compare distances between img@0 and all others\\n    for i in range(1, len(sample_embeddings)):\\n        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\\n    # As the correct img will be at distances_from_img_to_test_against index 0 (sample_imgs index 1),\\n    # If the smallest distance in distances_from_img_to_test_against is at index 0, \\n    # we know the one shot test got the right answer\\n    is_min = distances_from_img_to_test_against[0] == min(distances_from_img_to_test_against)\\n    is_max = distances_from_img_to_test_against[0] == max(distances_from_img_to_test_against)\\n    return int(is_min and not is_max)\\n    \\ndef n_way_accuracy_prototypes(n_val, n_way, network):\\n    num_correct = 0\\n    \\n    for val_step in range(n_val):\\n        num_correct += load_one_shot_test_batch_prototypes(n_way, network)\\n        \\n    accuracy = num_correct / n_val * 100\\n        \\n    return accuracy\\n\\ndef load_one_shot_test_batch_prototypes(n_way, network):\\n    \\n    labels = np.unique(y_test)\\n    # Reduce the label set down from size n_classes to n_samples \\n    labels = np.random.choice(labels, size = n_way, replace = False)\\n\\n    # Choose a class as the test image\\n    label = random.choice(labels)\\n    # Find all images of the chosen test class\\n    imgs_of_label = np.where(y_test == label)[0]\\n\\n    # Randomly select a test image of the selected class, return it's index\\n    img_of_label_idx = random.choice(imgs_of_label)\\n\\n    # Expand the array at the selected indexes into useable images\\n    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\\n    \\n    sample_embeddings = []\\n    # Get the anchor image embedding\\n    anchor_prototype = network.predict(img_of_label)\\n    sample_embeddings.append(anchor_prototype)\\n    \\n    # Get the prototype embedding for the positive class\\n    positive_prototype = prototypes[label]\\n \\n    sample_embeddings.append(positive_prototype)\\n    \\n    # Get the negative prototype embeddings\\n    # Remove the selected test class from the list of labels based on it's index \\n    label_idx_in_labels = np.where(labels == label)[0]\\n    other_labels = np.delete(labels, label_idx_in_labels)\\n    \\n    # Get the embedding for each of the remaining negatives\\n    for other_label in other_labels:\\n        negative_prototype = prototypes[other_label]\\n        sample_embeddings.append(negative_prototype)\\n                \\n    correct = test_one_shot_prototypes(network, sample_embeddings)\\n\\n    return correct\\n\\n\\ndef visualise_n_way_prototypes(n_samples, network):\\n    labels = np.unique(y_test)\\n    # Reduce the label set down from size n_classes to n_samples \\n    labels = np.random.choice(labels, size = n_samples, replace = False)\\n\\n    # Choose a class as the test image\\n    label = random.choice(labels)\\n    # Find all images of the chosen test class\\n    imgs_of_label = np.where(y_test == label)[0]\\n\\n    # Randomly select a test image of the selected class, return it's index\\n    img_of_label_idx = random.choice(imgs_of_label)\\n\\n    # Get another image idx that we know is of the test class for the sample set\\n    label_sample_img_idx = random.choice(imgs_of_label)\\n\\n    # Expand the array at the selected indexes into useable images\\n    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\\n    label_sample_img = np.expand_dims(x_test[label_sample_img_idx],axis=0)\\n    \\n    # Make the first img in the sample set the chosen test image, the second the other image\\n    sample_imgs = np.empty((0, x_test_w_h))\\n    sample_imgs = np.append(sample_imgs, img_of_label, axis=0)\\n    sample_imgs = np.append(sample_imgs, label_sample_img, axis=0)\\n    \\n    sample_embeddings = []\\n    \\n    # Get the anchor embedding image\\n    anchor_prototype = network.predict(img_of_label)\\n    sample_embeddings.append(anchor_prototype)\\n    \\n    # Get the prototype embedding for the positive class\\n    positive_prototype = prototypes[label]\\n    sample_embeddings.append(positive_prototype)\\n\\n    # Get the negative prototype embeddings\\n    # Remove the selected test class from the list of labels based on it's index \\n    label_idx_in_labels = np.where(labels == label)[0]\\n    other_labels = np.delete(labels, label_idx_in_labels)\\n    # Get the embedding for each of the remaining negatives\\n    for other_label in other_labels:\\n        negative_prototype = prototypes[other_label]\\n        sample_embeddings.append(negative_prototype)\\n        \\n        # Find all images of the other class\\n        imgs_of_other_label = np.where(y_test == other_label)[0]\\n        # Randomly select an image of the selected class, return it's index\\n        another_sample_img_idx = random.choice(imgs_of_other_label)\\n        # Expand the array at the selected index into useable images\\n        another_sample_img = np.expand_dims(x_test[another_sample_img_idx],axis=0)\\n        # Add the image to the support set\\n        sample_imgs = np.append(sample_imgs, another_sample_img, axis=0)\\n    \\n    distances_from_img_to_test_against = []\\n    \\n    # As the img to test against is in index 0, we compare distances between img@0 and all others\\n    for i in range(1, len(sample_embeddings)):\\n        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\\n        \\n    # + 1 as distances_from_img_to_test_against doesn't include the test image\\n    min_index = distances_from_img_to_test_against.index(min(distances_from_img_to_test_against)) + 1\\n    \\n    return sample_imgs, min_index\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More fns unused as to be adapted\n",
    "\n",
    "'''def generate_prototypes(x_data, y_data, embedding_model):\n",
    "    classes = np.unique(y_data)\n",
    "    prototypes = {}\n",
    "\n",
    "    for c in classes:\n",
    "        #c = classes[0]\n",
    "        # Find all images of the chosen test class\n",
    "        locations_of_c = np.where(y_data == c)[0]\n",
    "\n",
    "        imgs_of_c = x_data[locations_of_c]\n",
    "\n",
    "        imgs_of_c_embeddings = embedding_model.predict(imgs_of_c)\n",
    "\n",
    "        # Get the median of the embeddings to generate a prototype for the class (reshaping for PCA)\n",
    "        prototype_for_c = np.median(imgs_of_c_embeddings, axis = 0).reshape(1, -1)\n",
    "        # Add it to the prototype dict\n",
    "        prototypes[c] = prototype_for_c\n",
    "        \n",
    "    return prototypes\n",
    "         \n",
    "def test_one_shot_prototypes(network, sample_embeddings):\n",
    "    distances_from_img_to_test_against = []\n",
    "    # As the img to test against is in index 0, we compare distances between img@0 and all others\n",
    "    for i in range(1, len(sample_embeddings)):\n",
    "        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\n",
    "    # As the correct img will be at distances_from_img_to_test_against index 0 (sample_imgs index 1),\n",
    "    # If the smallest distance in distances_from_img_to_test_against is at index 0, \n",
    "    # we know the one shot test got the right answer\n",
    "    is_min = distances_from_img_to_test_against[0] == min(distances_from_img_to_test_against)\n",
    "    is_max = distances_from_img_to_test_against[0] == max(distances_from_img_to_test_against)\n",
    "    return int(is_min and not is_max)\n",
    "    \n",
    "def n_way_accuracy_prototypes(n_val, n_way, network):\n",
    "    num_correct = 0\n",
    "    \n",
    "    for val_step in range(n_val):\n",
    "        num_correct += load_one_shot_test_batch_prototypes(n_way, network)\n",
    "        \n",
    "    accuracy = num_correct / n_val * 100\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "def load_one_shot_test_batch_prototypes(n_way, network):\n",
    "    \n",
    "    labels = np.unique(y_test)\n",
    "    # Reduce the label set down from size n_classes to n_samples \n",
    "    labels = np.random.choice(labels, size = n_way, replace = False)\n",
    "\n",
    "    # Choose a class as the test image\n",
    "    label = random.choice(labels)\n",
    "    # Find all images of the chosen test class\n",
    "    imgs_of_label = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select a test image of the selected class, return it's index\n",
    "    img_of_label_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Expand the array at the selected indexes into useable images\n",
    "    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\n",
    "    \n",
    "    sample_embeddings = []\n",
    "    # Get the anchor image embedding\n",
    "    anchor_prototype = network.predict(img_of_label)\n",
    "    sample_embeddings.append(anchor_prototype)\n",
    "    \n",
    "    # Get the prototype embedding for the positive class\n",
    "    positive_prototype = prototypes[label]\n",
    " \n",
    "    sample_embeddings.append(positive_prototype)\n",
    "    \n",
    "    # Get the negative prototype embeddings\n",
    "    # Remove the selected test class from the list of labels based on it's index \n",
    "    label_idx_in_labels = np.where(labels == label)[0]\n",
    "    other_labels = np.delete(labels, label_idx_in_labels)\n",
    "    \n",
    "    # Get the embedding for each of the remaining negatives\n",
    "    for other_label in other_labels:\n",
    "        negative_prototype = prototypes[other_label]\n",
    "        sample_embeddings.append(negative_prototype)\n",
    "                \n",
    "    correct = test_one_shot_prototypes(network, sample_embeddings)\n",
    "\n",
    "    return correct\n",
    "\n",
    "\n",
    "def visualise_n_way_prototypes(n_samples, network):\n",
    "    labels = np.unique(y_test)\n",
    "    # Reduce the label set down from size n_classes to n_samples \n",
    "    labels = np.random.choice(labels, size = n_samples, replace = False)\n",
    "\n",
    "    # Choose a class as the test image\n",
    "    label = random.choice(labels)\n",
    "    # Find all images of the chosen test class\n",
    "    imgs_of_label = np.where(y_test == label)[0]\n",
    "\n",
    "    # Randomly select a test image of the selected class, return it's index\n",
    "    img_of_label_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Get another image idx that we know is of the test class for the sample set\n",
    "    label_sample_img_idx = random.choice(imgs_of_label)\n",
    "\n",
    "    # Expand the array at the selected indexes into useable images\n",
    "    img_of_label = np.expand_dims(x_test[img_of_label_idx],axis=0)\n",
    "    label_sample_img = np.expand_dims(x_test[label_sample_img_idx],axis=0)\n",
    "    \n",
    "    # Make the first img in the sample set the chosen test image, the second the other image\n",
    "    sample_imgs = np.empty((0, x_test_w_h))\n",
    "    sample_imgs = np.append(sample_imgs, img_of_label, axis=0)\n",
    "    sample_imgs = np.append(sample_imgs, label_sample_img, axis=0)\n",
    "    \n",
    "    sample_embeddings = []\n",
    "    \n",
    "    # Get the anchor embedding image\n",
    "    anchor_prototype = network.predict(img_of_label)\n",
    "    sample_embeddings.append(anchor_prototype)\n",
    "    \n",
    "    # Get the prototype embedding for the positive class\n",
    "    positive_prototype = prototypes[label]\n",
    "    sample_embeddings.append(positive_prototype)\n",
    "\n",
    "    # Get the negative prototype embeddings\n",
    "    # Remove the selected test class from the list of labels based on it's index \n",
    "    label_idx_in_labels = np.where(labels == label)[0]\n",
    "    other_labels = np.delete(labels, label_idx_in_labels)\n",
    "    # Get the embedding for each of the remaining negatives\n",
    "    for other_label in other_labels:\n",
    "        negative_prototype = prototypes[other_label]\n",
    "        sample_embeddings.append(negative_prototype)\n",
    "        \n",
    "        # Find all images of the other class\n",
    "        imgs_of_other_label = np.where(y_test == other_label)[0]\n",
    "        # Randomly select an image of the selected class, return it's index\n",
    "        another_sample_img_idx = random.choice(imgs_of_other_label)\n",
    "        # Expand the array at the selected index into useable images\n",
    "        another_sample_img = np.expand_dims(x_test[another_sample_img_idx],axis=0)\n",
    "        # Add the image to the support set\n",
    "        sample_imgs = np.append(sample_imgs, another_sample_img, axis=0)\n",
    "    \n",
    "    distances_from_img_to_test_against = []\n",
    "    \n",
    "    # As the img to test against is in index 0, we compare distances between img@0 and all others\n",
    "    for i in range(1, len(sample_embeddings)):\n",
    "        distances_from_img_to_test_against.append(compute_dist(sample_embeddings[0], sample_embeddings[i]))\n",
    "        \n",
    "    # + 1 as distances_from_img_to_test_against doesn't include the test image\n",
    "    min_index = distances_from_img_to_test_against.index(min(distances_from_img_to_test_against)) + 1\n",
    "    \n",
    "    return sample_imgs, min_index'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fatty-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding model... \n",
      "\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 369, 496, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 369, 496, 16)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 184, 248, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 184, 248, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 184, 248, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 92, 124, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 92, 124, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 90, 122, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 45, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 45, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 43, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 21, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 21, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 19, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 9, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 9, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 107,680\n",
      "Trainable params: 107,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Generating SNN... \n",
      "\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 369, 496, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 369, 496, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           [(None, 369, 496, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_12 (Functional)           (None, 32)           107680      input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96)           0           model_12[0][0]                   \n",
      "                                                                 model_12[1][0]                   \n",
      "                                                                 model_12[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 107,680\n",
      "Trainable params: 107,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Evaluating the model without training for a baseline...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vignesh\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "num_classes = 354 #should be made dynamic\n",
    "batch_size = 256\n",
    "epochs = 15 #100\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "# val_steps = int(x_test.shape[0]/batch_size)\n",
    "alpha = 0.2\n",
    "num_hard = int(batch_size * 0.5) # Number of semi-hard triplet examples in the batch\n",
    "lr = 0.00006\n",
    "optimiser = 'Adam'\n",
    "emb_size = 32 # 10 in mnist\n",
    "input_size = (369,496,1)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # Create the embedding model\n",
    "    print(\"Generating embedding model... \\n\")\n",
    "    embedding_model = make_embedding_model(emb_size=emb_size) #maybe dec input size (369,496) \n",
    "    \n",
    "    print(\"\\nGenerating SNN... \\n\")\n",
    "    # Create the SNN\n",
    "    siamese_net = SNN(embedding_model)\n",
    "    # Compile the SNN\n",
    "    optimiser_obj = Adam(lr = lr)\n",
    "    siamese_net.compile(loss=triplet_loss, optimizer= optimiser_obj)\n",
    "    \n",
    "    # Store visualisations of the embeddings using PCA for display next to \"after training\" for comparisons\n",
    "    num_vis = 500 # Take only the first num_vis elements of the test set to visualise\n",
    "#     embeddings_before_train = embedding_model.predict(get_first_500())\n",
    "#     pca = PCA(n_components=2)\n",
    "#     decomposed_embeddings_before = pca.fit_transform(embeddings_before_train)\n",
    "\n",
    "print(\"\\nEvaluating the model without training for a baseline...\\n\")\n",
    "evaluate(embedding_model)\n",
    "\n",
    "#### DO CALLBACKS LATER\n",
    "\n",
    "# Save model configs to JSON\n",
    "# model_json = siamese_net.to_json()\n",
    "# with open(os.path.join(logdir, \"siamese_config.json\"), \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "#     json_file.close()\n",
    "    \n",
    "# model_json = embedding_model.to_json()\n",
    "# with open(os.path.join(logdir, \"embedding_config.json\"), \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "#     json_file.close()\n",
    "    \n",
    "# hyperparams = {'batch_size' : batch_size,\n",
    "#               'epochs' : epochs, \n",
    "#                'steps_per_epoch' : steps_per_epoch, \n",
    "#                'val_steps' : val_steps, \n",
    "#                'alpha' : alpha, \n",
    "#                'num_hard' : num_hard, \n",
    "#                'optimiser' : optimiser,\n",
    "#                'lr' : lr,\n",
    "#                'emb_size' : emb_size\n",
    "#               }\n",
    "\n",
    "# with open(os.path.join(logdir, \"hyperparams.json\"), \"w\") as json_file:\n",
    "#     json.dump(hyperparams, json_file)\n",
    "\n",
    "def delete_older_model_files(filepath):\n",
    "    \n",
    "    model_dir = filepath.split(\"emb_model\")[0]\n",
    "    \n",
    "    # Get model files\n",
    "    model_files = os.listdir(model_dir)\n",
    "\n",
    "    # Get only the emb_model files\n",
    "    emb_model_files = [file for file in model_files if \"emb_model\" in file]\n",
    "    # Get the epoch nums of the emb_model_files\n",
    "    emb_model_files_epoch_nums = [int(file.split(\"-\")[1].split(\".h5\")[0]) for file in emb_model_files]\n",
    "\n",
    "    # Find all the snn model files\n",
    "    snn_model_files = [file for file in model_files if \"snn_model\" in file]\n",
    "\n",
    "    # Sort, get highest epoch num\n",
    "    emb_model_files_epoch_nums.sort()\n",
    "    highest_epoch_num = str(emb_model_files_epoch_nums[-1]).zfill(2)\n",
    "\n",
    "    # Filter the emb_model and snn_model file lists to remove the highest epoch number ones\n",
    "    emb_model_files_without_highest = [file for file in emb_model_files if highest_epoch_num not in file]\n",
    "    snn_model_files_without_highest = [file for file in snn_model_files if (\"-\" + highest_epoch_num + \"-\") not in file]\n",
    "\n",
    "    # Delete the non-highest model files from the subdir\n",
    "    if len(emb_model_files_without_highest) != 0:\n",
    "        print(\"Deleting previous best model file\")\n",
    "    for model_file_list in [emb_model_files_without_highest, snn_model_files_without_highest]:\n",
    "        for file in model_file_list:\n",
    "            os.remove(os.path.join(model_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "current-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_first_500()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "secure-saudi",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-9f2b259887ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "surrounded-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_30/bias:0', 'conv2d_31/bias:0', 'conv2d_32/bias:0', 'conv2d_33/bias:0', 'conv2d_34/bias:0', 'dense_6/bias:0'] when minimizing the loss.\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 1 iterations: 0.3 mins, Train Loss: 0.5427433252334595\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_30/bias:0', 'conv2d_31/bias:0', 'conv2d_32/bias:0', 'conv2d_33/bias:0', 'conv2d_34/bias:0', 'dense_6/bias:0'] when minimizing the loss.\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 2 iterations: 0.8 mins, Train Loss: 0.5420041084289551\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_30/bias:0', 'conv2d_31/bias:0', 'conv2d_32/bias:0', 'conv2d_33/bias:0', 'conv2d_34/bias:0', 'dense_6/bias:0'] when minimizing the loss.\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 3 iterations: 1.3 mins, Train Loss: 0.5412631630897522\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 4 iterations: 1.7 mins, Train Loss: 0.5405215620994568\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 5 iterations: 2.2 mins, Train Loss: 0.5397797226905823\n",
      "Got only 9 triplets, increasing alpha\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 6 iterations: 2.7 mins, Train Loss: 0.5390379428863525\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 7 iterations: 3.1 mins, Train Loss: 0.5382964611053467\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 8 iterations: 3.6 mins, Train Loss: 0.5375552773475647\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 9 iterations: 4.0 mins, Train Loss: 0.5368145704269409\n",
      "\n",
      " ------------- \n",
      "\n",
      "[0] Time for 10 iterations: 4.5 mins, Train Loss: 0.5360743999481201\n",
      "-------------------------------------\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# Make the model work over the two GPUs we have\n",
    "# num_gpus = get_num_gpus()\n",
    "# parallel_snn = multi_gpu_model(siamese_net, gpus = num_gpus)\n",
    "# batch_per_gpu = int(batch_size / num_gpus)\n",
    "siamese_net.compile(loss=triplet_loss, optimizer= optimiser_obj)\n",
    "\n",
    "n_iter = 10 #1000\n",
    "n_iteration = 0\n",
    "evaluate_every = 2\n",
    "t_start = time.time() \n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "    triplets = create_hard_batch(batch_size=100,alpha=0.2)\n",
    "    triplet_count = triplets[0].shape[0]\n",
    "    if(triplet_count < 0.1*100):\n",
    "        print(\"Got only\", triplet_count,\"triplets, increasing alpha\")\n",
    "        alpha += 0.25\n",
    "    #Check alpha here and update\n",
    "    loss = siamese_net.train_on_batch(triplets, None)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        probs,yprob = compute_probs(embedding_model,x_test[:200], y_test[:200])\n",
    "        #fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "        #draw_roc(fpr, tpr)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "representative-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do analysis\n",
    "#other funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-prototype",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
